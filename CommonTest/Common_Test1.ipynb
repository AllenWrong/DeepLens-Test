{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a275ec9d",
   "metadata": {
    "id": "a275ec9d"
   },
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4da6a957",
   "metadata": {
    "id": "4da6a957"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.backends import cudnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edb3f8f",
   "metadata": {
    "id": "3edb3f8f"
   },
   "source": [
    "**Set the seed. Let the result can be Reproducible**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4bb5c79",
   "metadata": {
    "id": "a4bb5c79"
   },
   "outputs": [],
   "source": [
    "seed = 20\n",
    "\n",
    "# set random seed\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d32443d6",
   "metadata": {
    "id": "d32443d6"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddb56d8",
   "metadata": {
    "id": "7ddb56d8"
   },
   "source": [
    "# Data Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3342ee46",
   "metadata": {
    "id": "3342ee46"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7467256",
   "metadata": {
    "id": "d7467256"
   },
   "source": [
    "## MyData class Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "245a4012",
   "metadata": {
    "id": "245a4012"
   },
   "outputs": [],
   "source": [
    "class MyData(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, data_dir, transform=None):\n",
    "        self.desc = pd.read_csv(csv_file)\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        print(self.transform)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.desc)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        path = os.path.join(self.data_dir, self.desc.iloc[item, 0])\n",
    "        x = np.load(path)[0]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        label = torch.tensor(self.desc.iloc[item, 1])\n",
    "        return x, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468aba70",
   "metadata": {
    "id": "468aba70"
   },
   "source": [
    "## Create Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e5669e",
   "metadata": {
    "id": "01e5669e"
   },
   "source": [
    "The file organization of this task dataset should be as follows:\n",
    "\n",
    "****\n",
    "```\n",
    "DeepLens-Test\n",
    "  |-- CommonTest\n",
    "     |-- dataset\n",
    "        |-- train\n",
    "           |-- no\n",
    "           |-- sphere\n",
    "           |-- vort\n",
    "        |-- val\n",
    "           |-- no\n",
    "           |-- sphere\n",
    "           |-- vort\n",
    "        |-- test description.csv\n",
    "        |-- train description.csv\n",
    "        |-- val description.csv\n",
    "```\n",
    "****\n",
    "\n",
    "`train description.csv` `test description.csv` and `val description.csv` is generate by program. I have provided it. Dataset can be get <a href=\"https://drive.google.com/file/d/1B_UZtU4W65ZViTJsLeFfvK-xXCYUhw2A/view\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89b80836",
   "metadata": {
    "id": "89b80836"
   },
   "outputs": [],
   "source": [
    "def index_of_class(classname):\n",
    "    if classname == \"no\":\n",
    "        return 0\n",
    "    elif classname == \"sphere\":\n",
    "        return 1\n",
    "    elif classname == \"vort\":\n",
    "        return 2\n",
    "    else:\n",
    "        raise Exception(\"unknown class name!\")\n",
    "\n",
    "\n",
    "def create_train_description(data_dir, train_rate=0.9, need_num=None):\n",
    "    \"\"\"create a description csv file. see \"./dataset/train description.csv\",\n",
    "    \"./dataset/val description.csv\". Some demo example can be find in demo.py\n",
    "\n",
    "    Args:\n",
    "        data_dir:\n",
    "            root directory of train or val dataset. Here,\n",
    "            it should be \"./dataset/train\"\n",
    "        train_rate:\n",
    "            rate of train set\n",
    "        need_num:\n",
    "            set the numbers of samples you need.\n",
    "    \"\"\"\n",
    "    class_dirs = os.listdir(data_dir)\n",
    "    line_train = \"path,label\\n\"\n",
    "    line_val = \"path,label\\n\"\n",
    "    for class_dir in class_dirs:\n",
    "        samples = os.listdir(os.path.join(data_dir, class_dir))[:need_num]\n",
    "\n",
    "        # split train set to train and val\n",
    "        end_idx = int(train_rate * len(samples))\n",
    "        random.shuffle(samples)\n",
    "        train_samples = samples[:end_idx]\n",
    "        val_samples = samples[end_idx:]\n",
    "\n",
    "        for sample in train_samples:\n",
    "            line_train += os.path.join(class_dir, sample) + \",\" + str(index_of_class(class_dir)) + \"\\n\"\n",
    "\n",
    "        for sample in val_samples:\n",
    "            line_val += os.path.join(class_dir, sample) + \",\" + str(index_of_class(class_dir)) + \"\\n\"\n",
    "\n",
    "    store_path = os.path.join(\"./dataset\", \"train description.csv\")\n",
    "    with open(store_path, \"w\") as f:\n",
    "        f.write(line_train)\n",
    "\n",
    "    if train_rate != 1:\n",
    "        store_path = os.path.join(\"./dataset\", \"val description.csv\")\n",
    "        with open(store_path, \"w\") as f:\n",
    "            f.write(line_val)\n",
    "\n",
    "\n",
    "def create_test_description(data_dir, need_num=None):\n",
    "    \"\"\"create a description csv file. see \"./dataset/test description.csv\".\n",
    "    Some demo example can be find in demo.py\n",
    "\n",
    "    Args:\n",
    "        data_dir:\n",
    "            root directory of train or val dataset. Here,\n",
    "            it should be \"./dataset/val\"\n",
    "        need_num:\n",
    "            set the numbers of samples you need.\n",
    "    \"\"\"\n",
    "    class_dirs = os.listdir(data_dir)\n",
    "\n",
    "    line = \"path,label\\n\"\n",
    "    for class_dir in class_dirs:\n",
    "        samples = os.listdir(os.path.join(data_dir, class_dir))[:need_num]\n",
    "\n",
    "        for sample in samples:\n",
    "            line += os.path.join(class_dir, sample) + \",\" + str(index_of_class(class_dir)) + \"\\n\"\n",
    "\n",
    "    store_path = os.path.join(\"./dataset\", \"test description.csv\")\n",
    "    with open(store_path, \"w\") as f:\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8222ea0f",
   "metadata": {
    "id": "8222ea0f"
   },
   "source": [
    "**run once is ok. If description files already exist, do not run this part.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eb3a068",
   "metadata": {
    "id": "1eb3a068"
   },
   "outputs": [],
   "source": [
    "# create_train_description(\"./dataset/train\")\n",
    "# create_test_description(\"./dataset/val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278a0735",
   "metadata": {
    "id": "278a0735"
   },
   "source": [
    "# Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0ecd5a3",
   "metadata": {
    "id": "f0ecd5a3"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torchvision import models\n",
    "from torch.nn import Conv2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870ceca9",
   "metadata": {
    "id": "870ceca9"
   },
   "source": [
    "This dataset is not complicated. So, simple deep model such as AlexNet, VGG, ResNet, DenseNet can be competent at this task. According to paper[1], for ResNet, the defining feature is that residual networks can skip layers all together in training. This helps speed up the learning rate of the network by allowing the network to train fewer layers in the initial stages of learning. ResNet is more computationally efficient than both VGG and DenseNet. Here, we use ResNet18.\n",
    "\n",
    "Many tasks have been benefit from transfer learning. Transfer learning can speed up the time of training models by reusing modules or parts of pretrained models. This not only speeds up the model training process, but also improves the training effect. By transfer learning, we use the pretrained ResNet18 on ImageNet as backbone. The we add a three layers mlp as a simple classifier. The model architecture look like this:\n",
    "\n",
    "<center><img src=\"https://cdn.jsdelivr.net/gh/AllenWrong/BlogCDN/img/res arch.png\" max-witdh=\"50%\" max-height=\"50%\"/></center>\n",
    "\n",
    "**[1]** Deep Learning the Morphology of Dark Matter Substructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91ddccb0",
   "metadata": {
    "id": "91ddccb0"
   },
   "outputs": [],
   "source": [
    "class ResNetClf(nn.Module):\n",
    "\n",
    "    def __init__(self, pre_trained):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pre_trained: True if want to use pretrained weight else false\n",
    "        \"\"\"\n",
    "        super(ResNetClf, self).__init__()\n",
    "        self.backbone = models.resnet18(pretrained=pre_trained)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 3)\n",
    "        )\n",
    "        self.backbone.conv1 = Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.backbone.fc = self.classifier\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa2680b",
   "metadata": {
    "id": "1aa2680b"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e6fec2",
   "metadata": {
    "id": "71e6fec2"
   },
   "source": [
    "- **data augmentation:** According paper[1], during training I use the data augmengtation via random translation and random rotation.\n",
    "\n",
    "\n",
    "- **batch_size:** I have tried batch_size=200, batch_size=64, batch_size=128. Results show that batch_size=128 same a better choice. Larger batch_size can improve the computational efficiency through the matrix multiply. More larger batch_size reduces the number of iterations required to compute all the training set, so the time required to achieve the same accuracy becomes larger, and the adjust of parameters becomes slow.\n",
    "\n",
    "\n",
    "- **num_epoch:** 50\n",
    "\n",
    "\n",
    "- **lr:** According to paper[1], I set the lr with value of 1e-4. If the AUC does not increase for four consecutive epochs, the learning rate will be multiplied by 0.7 to decay.\n",
    "\n",
    "\n",
    "- **train:** When one epoch has finished, model will evaluate it's current performance on the validation dataset.  \n",
    "\n",
    "\n",
    "**Final auc is 98.95%, acc is 92.87%**, which is an acceptable result.\n",
    "\n",
    "**[1]** Deep Learning the Morphology of Dark Matter Substructure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3428780c",
   "metadata": {
    "id": "3428780c"
   },
   "source": [
    "## Training Config Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4e243e4",
   "metadata": {
    "id": "c4e243e4"
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    num_epochs = 50\n",
    "    batch_size = 128\n",
    "    # reference from paper \"Deep Learning the Morphology of Dark Matter Substructure\"\n",
    "    lr = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa716c65",
   "metadata": {
    "id": "aa716c65"
   },
   "source": [
    "## Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "826c8ec6",
   "metadata": {
    "id": "826c8ec6"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from utils import check_accuracy, save_checkpoint\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeaefd0",
   "metadata": {
    "id": "eaeaefd0"
   },
   "source": [
    "## Train Function Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6d582c9",
   "metadata": {
    "id": "d6d582c9"
   },
   "outputs": [],
   "source": [
    "def train_fn(cfg, train_loader, val_loader, model, optimizer, criterion, need_flatten=False):\n",
    "    \"\"\"\n",
    "    train function\n",
    "    \"\"\"\n",
    "\n",
    "    acc_per_epoch = []\n",
    "    max_auc = 0.0\n",
    "\n",
    "    # lr scheduler\n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode=\"max\",\n",
    "        factor=0.8,\n",
    "        patience=4,\n",
    "        threshold=0.001,\n",
    "        min_lr=1e-5,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    for epoch in range(cfg.num_epochs):\n",
    "        losses_per_batch = []\n",
    "        start_time = time.time()\n",
    "\n",
    "        # mini batch training\n",
    "        p_bar = tqdm(enumerate(train_loader), leave=False, total=len(train_loader), file=sys.stdout)\n",
    "        for batch_idx, (x_batch, y_batch) in p_bar:\n",
    "            # move data to gpu if cuda is available\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            if need_flatten:\n",
    "                x_batch = x_batch.reshape(x_batch.shape[0], -1)\n",
    "\n",
    "            # forward\n",
    "            scores = model.forward(x_batch)\n",
    "            loss = criterion(scores, y_batch)\n",
    "            losses_per_batch.append(loss.item())\n",
    "\n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # gradient descent step\n",
    "            optimizer.step()\n",
    "\n",
    "        # compute acc and loss\n",
    "        cur_acc, auc, _, _ = check_accuracy(val_loader, model, device, need_flatten)\n",
    "        mean_loss = sum(losses_per_batch) / len(losses_per_batch)\n",
    "        acc_per_epoch.append(cur_acc)\n",
    "\n",
    "        # lr scheduler\n",
    "        scheduler.step(auc)\n",
    "\n",
    "        # save model\n",
    "        if epoch >= 20 and auc > max_auc:\n",
    "            checkpoint = {\n",
    "                \"model\": model.state_dict(),\n",
    "                \"optimizer\": optimizer.state_dict()\n",
    "            }\n",
    "            print(f\"epoch: [{epoch + 1}/{cfg.num_epochs}], \", end=\"\")\n",
    "            save_checkpoint(checkpoint, \"./checkpoint/best_auc_model.pth.tar\")\n",
    "            max_auc = auc\n",
    "\n",
    "        # print log\n",
    "        end_time = time.time()\n",
    "        print(f\"epoch: [{epoch + 1}/{cfg.num_epochs}], \"\n",
    "              f\"loss: {mean_loss:.8f}, \"\n",
    "              f\"val acc: {cur_acc.item():.4f}, \"\n",
    "              f\"val auc: {auc:.4f}, \"\n",
    "              f\"time used: {(end_time - start_time)/60:.4f}m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a68e34a",
   "metadata": {
    "id": "5a68e34a"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59f0e6f8",
   "metadata": {
    "id": "59f0e6f8"
   },
   "outputs": [],
   "source": [
    "# create a config\n",
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd396f3",
   "metadata": {
    "id": "bdd396f3"
   },
   "source": [
    "### Data Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a4ef737",
   "metadata": {
    "id": "0a4ef737"
   },
   "outputs": [],
   "source": [
    "train_dir = \"./dataset/train\"\n",
    "val_dir = \"./dataset/train\"\n",
    "test_dir = \"./dataset/val\"\n",
    "\n",
    "train_desc_dir = \"./dataset/train description.csv\"\n",
    "val_desc_dir = \"./dataset/val description.csv\"\n",
    "test_desc_dir = \"./dataset/test description.csv\"\n",
    "\n",
    "# transform\n",
    "train_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomAffine(degrees=(0, 180), translate=(0.2, 0.2)),\n",
    "        transforms.Resize((150, 150))\n",
    "    ])\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((150, 150))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fc073e0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3fc073e0",
    "outputId": "2b750767-1393-43f4-b351-f471b485d2f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    ToTensor()\n",
      "    RandomAffine(degrees=[0.0, 180.0], translate=(0.2, 0.2))\n",
      "    Resize(size=(150, 150), interpolation=bilinear, max_size=None, antialias=None)\n",
      ")\n",
      "Compose(\n",
      "    ToTensor()\n",
      "    Resize(size=(150, 150), interpolation=bilinear, max_size=None, antialias=None)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "train_set = MyData(train_desc_dir, train_dir, transform=train_transform)\n",
    "val_set = MyData(val_desc_dir, val_dir, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=cfg.batch_size, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_set, batch_size=cfg.batch_size, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfad72c",
   "metadata": {
    "id": "edfad72c"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e046a393-30c8-4f66-8ec4-75eab9b7f5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"checkpoint\"):\n",
    "    os.makedirs(\"checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "deaaf305",
   "metadata": {
    "id": "deaaf305"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: [1/50], loss: 1.09917662, val acc: 0.3860, val auc: 0.5597, time used: 5.7564m\n",
      "epoch: [2/50], loss: 1.07380610, val acc: 0.4153, val auc: 0.6187, time used: 5.7530m\n",
      "epoch: [3/50], loss: 0.95937999, val acc: 0.4490, val auc: 0.6858, time used: 5.7555m\n",
      "epoch: [4/50], loss: 0.82470558, val acc: 0.5893, val auc: 0.7934, time used: 5.7500m\n",
      "epoch: [5/50], loss: 0.71235942, val acc: 0.7147, val auc: 0.8870, time used: 5.7498m\n",
      "epoch: [6/50], loss: 0.62316861, val acc: 0.7057, val auc: 0.8833, time used: 5.7506m\n",
      "epoch: [7/50], loss: 0.54778413, val acc: 0.7553, val auc: 0.9157, time used: 5.7513m\n",
      "epoch: [8/50], loss: 0.49973536, val acc: 0.8123, val auc: 0.9439, time used: 5.7525m\n",
      "epoch: [9/50], loss: 0.46813309, val acc: 0.8207, val auc: 0.9498, time used: 5.7574m\n",
      "epoch: [10/50], loss: 0.43722969, val acc: 0.8443, val auc: 0.9578, time used: 5.7484m\n",
      "epoch: [11/50], loss: 0.41298067, val acc: 0.7997, val auc: 0.9449, time used: 5.7475m\n",
      "epoch: [12/50], loss: 0.38993755, val acc: 0.8263, val auc: 0.9571, time used: 5.7488m\n",
      "epoch: [13/50], loss: 0.37305418, val acc: 0.8553, val auc: 0.9680, time used: 5.7474m\n",
      "epoch: [14/50], loss: 0.36269888, val acc: 0.8510, val auc: 0.9632, time used: 5.7454m\n",
      "epoch: [15/50], loss: 0.34930719, val acc: 0.8573, val auc: 0.9666, time used: 5.7541m\n",
      "epoch: [16/50], loss: 0.34085144, val acc: 0.8570, val auc: 0.9660, time used: 5.7516m\n",
      "epoch: [17/50], loss: 0.31987531, val acc: 0.8673, val auc: 0.9679, time used: 5.7626m\n",
      "Epoch    18: reducing learning rate of group 0 to 8.0000e-05.\n",
      "epoch: [18/50], loss: 0.31534035, val acc: 0.8597, val auc: 0.9664, time used: 5.7573m\n",
      "epoch: [19/50], loss: 0.30151504, val acc: 0.8920, val auc: 0.9775, time used: 5.7487m\n",
      "epoch: [20/50], loss: 0.28990176, val acc: 0.8853, val auc: 0.9761, time used: 5.7544m\n",
      "epoch: [21/50], ====> Save checkpoint in ./checkpoint/best_auc_model.pth.tar\n",
      "epoch: [21/50], loss: 0.28338485, val acc: 0.8807, val auc: 0.9723, time used: 5.7609m\n",
      "epoch: [22/50], ====> Save checkpoint in ./checkpoint/best_auc_model.pth.tar\n",
      "epoch: [22/50], loss: 0.27309732, val acc: 0.8947, val auc: 0.9798, time used: 5.7588m\n",
      "epoch: [23/50], loss: 0.27709280, val acc: 0.8750, val auc: 0.9721, time used: 5.7478m\n",
      "epoch: [24/50], loss: 0.26795964, val acc: 0.8800, val auc: 0.9754, time used: 5.7530m\n",
      "epoch: [25/50], loss: 0.26300544, val acc: 0.8943, val auc: 0.9789, time used: 5.7575m\n",
      "epoch: [26/50], loss: 0.25613450, val acc: 0.8917, val auc: 0.9781, time used: 5.7519m\n",
      "epoch: [27/50], ====> Save checkpoint in ./checkpoint/best_auc_model.pth.tar\n",
      "epoch: [27/50], loss: 0.25407544, val acc: 0.8937, val auc: 0.9813, time used: 5.7632m\n",
      "epoch: [28/50], ====> Save checkpoint in ./checkpoint/best_auc_model.pth.tar\n",
      "epoch: [28/50], loss: 0.24581066, val acc: 0.9040, val auc: 0.9824, time used: 5.7621m\n",
      "epoch: [29/50], ====> Save checkpoint in ./checkpoint/best_auc_model.pth.tar\n",
      "epoch: [29/50], loss: 0.24589001, val acc: 0.9047, val auc: 0.9837, time used: 5.7679m\n",
      "epoch: [30/50], loss: 0.24426743, val acc: 0.8913, val auc: 0.9800, time used: 5.7542m\n",
      "epoch: [31/50], loss: 0.23757527, val acc: 0.9037, val auc: 0.9823, time used: 5.7503m\n",
      "epoch: [32/50], ====> Save checkpoint in ./checkpoint/best_auc_model.pth.tar\n",
      "epoch: [32/50], loss: 0.23634910, val acc: 0.9077, val auc: 0.9843, time used: 5.7619m\n",
      "epoch: [33/50], ====> Save checkpoint in ./checkpoint/best_auc_model.pth.tar\n",
      "epoch: [33/50], loss: 0.23056181, val acc: 0.9007, val auc: 0.9844, time used: 5.7606m\n",
      "epoch: [34/50], ====> Save checkpoint in ./checkpoint/best_auc_model.pth.tar\n",
      "epoch: [34/50], loss: 0.22650623, val acc: 0.9040, val auc: 0.9851, time used: 5.7625m\n",
      "epoch: [35/50], loss: 0.22662611, val acc: 0.9120, val auc: 0.9851, time used: 5.7515m\n",
      "epoch: [36/50], ====> Save checkpoint in ./checkpoint/best_auc_model.pth.tar\n",
      "epoch: [36/50], loss: 0.22237982, val acc: 0.9190, val auc: 0.9876, time used: 5.7643m\n",
      "epoch: [37/50], loss: 0.22068317, val acc: 0.9130, val auc: 0.9858, time used: 5.7520m\n",
      "epoch: [38/50], loss: 0.21826052, val acc: 0.9143, val auc: 0.9869, time used: 5.7496m\n",
      "epoch: [39/50], loss: 0.21323591, val acc: 0.9080, val auc: 0.9857, time used: 5.7512m\n",
      "epoch: [40/50], loss: 0.21264665, val acc: 0.9210, val auc: 0.9872, time used: 5.7484m\n",
      "Epoch    41: reducing learning rate of group 0 to 6.4000e-05.\n",
      "epoch: [41/50], loss: 0.20884565, val acc: 0.9137, val auc: 0.9867, time used: 5.7467m\n",
      "epoch: [42/50], loss: 0.20281992, val acc: 0.9127, val auc: 0.9864, time used: 5.7506m\n",
      "epoch: [43/50], ====> Save checkpoint in ./checkpoint/best_auc_model.pth.tar\n",
      "epoch: [43/50], loss: 0.19693113, val acc: 0.9223, val auc: 0.9879, time used: 5.7630m\n",
      "epoch: [44/50], loss: 0.19816629, val acc: 0.9120, val auc: 0.9873, time used: 5.7517m\n",
      "epoch: [45/50], loss: 0.19221107, val acc: 0.9190, val auc: 0.9866, time used: 5.7550m\n",
      "epoch: [46/50], ====> Save checkpoint in ./checkpoint/best_auc_model.pth.tar\n",
      "epoch: [46/50], loss: 0.18756298, val acc: 0.9230, val auc: 0.9888, time used: 5.7621m\n",
      "epoch: [47/50], loss: 0.18693715, val acc: 0.9150, val auc: 0.9854, time used: 5.7503m\n",
      "epoch: [48/50], loss: 0.18934451, val acc: 0.9197, val auc: 0.9883, time used: 5.7477m\n",
      "epoch: [49/50], loss: 0.18429150, val acc: 0.9250, val auc: 0.9881, time used: 5.7477m\n",
      "epoch: [50/50], loss: 0.18301214, val acc: 0.9267, val auc: 0.9882, time used: 5.7501m\n"
     ]
    }
   ],
   "source": [
    "model = ResNetClf(True).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=cfg.lr)\n",
    "\n",
    "train_fn(cfg, train_loader, val_loader, model, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41d3545",
   "metadata": {
    "id": "d41d3545"
   },
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b3c84a2",
   "metadata": {
    "id": "4b3c84a2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from utils import check_accuracy, load_checkpoint, plot_roc\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb3fae8b",
   "metadata": {
    "id": "cb3fae8b"
   },
   "outputs": [],
   "source": [
    "# create a config\n",
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02b7aaa",
   "metadata": {
    "id": "a02b7aaa"
   },
   "source": [
    "## Test Data Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50fd417",
   "metadata": {
    "id": "c50fd417"
   },
   "source": [
    "**You can get pretrained weight <a href=\"https://drive.google.com/file/d/1CVxOc0YovdcNGguXcSXneIFS9Gy9CnHz/view?usp=sharing\">here</a>**\n",
    "\n",
    "**After downloading it, add it to the directory \"./checkpoint\". Then you can perform the evaluation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f0421b5",
   "metadata": {
    "id": "2f0421b5",
    "outputId": "25eda648-f2a3-4a84-90bd-ff551280e1b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    ToTensor()\n",
      "    Resize(size=(150, 150), interpolation=bilinear, max_size=None, antialias=None)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "testset_dir = \"./dataset/val\"\n",
    "testdesc_dir = \"./dataset/test description.csv\"\n",
    "pretrained_model = \"./checkpoint/best_auc_model.pth.tar\"\n",
    "\n",
    "test_tranform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((150, 150))\n",
    "])\n",
    "\n",
    "test_set = MyData(testdesc_dir, testset_dir, transform=test_tranform)\n",
    "test_loader = DataLoader(test_set, batch_size=cfg.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4fdb3b5d",
   "metadata": {
    "id": "4fdb3b5d",
    "outputId": "f6a098a4-337d-4909-a817-dc90fc83a0f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Load model from ./checkpoint/best_auc_model.pth.tar\n"
     ]
    }
   ],
   "source": [
    "model = ResNetClf(False).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=cfg.lr)\n",
    "load_checkpoint(pretrained_model, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a1517a4",
   "metadata": {
    "id": "0a1517a4",
    "outputId": "8db83f80-f2a1-41f6-9116-01758374078d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9286666666666668, auc: 0.98946832\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc, auc, y_true, y_pred = check_accuracy(test_loader, model, device)\n",
    "print(f\"acc: {acc.item()}, auc: {auc}\")\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "\n",
    "plot_roc(fpr, tpr, auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e8232b",
   "metadata": {
    "id": "c3e8232b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Common Test1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
