{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a275ec9d",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4da6a957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.backends import cudnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edb3f8f",
   "metadata": {},
   "source": [
    "**Set the seed. Let the result can be Reproducible**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4bb5c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 20\n",
    "\n",
    "# set random seed\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d32443d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddb56d8",
   "metadata": {},
   "source": [
    "# Data Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3342ee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7467256",
   "metadata": {},
   "source": [
    "## MyData class Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "245a4012",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyData(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, data_dir, transform=None):\n",
    "        self.desc = pd.read_csv(csv_file)\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        print(self.transform)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.desc)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        path = os.path.join(self.data_dir, self.desc.iloc[item, 0])\n",
    "        x = np.load(path)[0]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        label = torch.tensor(self.desc.iloc[item, 1])\n",
    "        return x, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468aba70",
   "metadata": {},
   "source": [
    "## Create Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e5669e",
   "metadata": {},
   "source": [
    "The file organization of this task dataset should be as follows:\n",
    "\n",
    "****\n",
    "```\n",
    "DeepLens-Test\n",
    "  |-- common test1\n",
    "     |-- dataset\n",
    "        |-- train\n",
    "           |-- no\n",
    "           |-- sphere\n",
    "           |-- vort\n",
    "        |-- val\n",
    "           |-- no\n",
    "           |-- sphere\n",
    "           |-- vort\n",
    "        |-- train description.csv\n",
    "        |-- val description.csv\n",
    "```\n",
    "****\n",
    "\n",
    "`train description.csv` and `val description.csv` is generate by program. I have provided it. Dataset can be get <a href=\"https://drive.google.com/file/d/1B_UZtU4W65ZViTJsLeFfvK-xXCYUhw2A/view\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b80836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_of_class(classname):\n",
    "    if classname == \"no\":\n",
    "        return 0\n",
    "    elif classname == \"sphere\":\n",
    "        return 1\n",
    "    elif classname == \"vort\":\n",
    "        return 2\n",
    "    else:\n",
    "        raise Exception(\"unknown class name!\")\n",
    "        \n",
    "\n",
    "def create_data_description(data_dir, need_num):\n",
    "    \"\"\"create a description csv file. see \"./dataset/train description.csv\"\n",
    "    or \"/dataset/val description.csv\". Some demo example can be find in demo.py\n",
    "\n",
    "    Args:\n",
    "        data_dir:\n",
    "            root directory of train or val dataset. Here,\n",
    "            it should be \"./dataset/train\", or \"./dataset/val\"\n",
    "        need_num:\n",
    "            set the numbers of samples you need.\n",
    "    \"\"\"\n",
    "\n",
    "    class_dirs = os.listdir(data_dir)\n",
    "    line = \"path,label\\n\"\n",
    "\n",
    "    for class_dir in class_dirs:\n",
    "        samples = os.listdir(os.path.join(data_dir, class_dir))[:need_num]\n",
    "        for sample in samples:\n",
    "            line += os.path.join(class_dir, sample) + \",\" + str(index_of_class(class_dir)) + \"\\n\"\n",
    "\n",
    "    prefix = data_dir.split(\"/\")[-1]\n",
    "    store_path = os.path.join(\"./dataset\", f\"{prefix} description.csv\")\n",
    "    with open(store_path, \"w\") as f:\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8222ea0f",
   "metadata": {},
   "source": [
    "**run once is ok. If description files already exist, do not run this part.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb3a068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_data_description(\"./dataset/train\", None)\n",
    "# create_data_description(\"./dataset/val\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278a0735",
   "metadata": {},
   "source": [
    "# Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0ecd5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torchvision import models\n",
    "from torch.nn import Conv2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870ceca9",
   "metadata": {},
   "source": [
    "This dataset is not complicated. So, simple deep model such as AlexNet, VGG, ResNet, DenseNet can be competent at this task. According to paper[1], for ResNet, the defining feature is that residual networks can skip layers all together in training. This helps speed up the learning rate of the network by allowing the network to train fewer layers in the initial stages of learning. ResNet is more computationally efficient than both VGG and DenseNet. Here, we use ResNet18.\n",
    "\n",
    "Many tasks have been benefit from transfer learning. Transfer learning can speed up the time of training models by reusing modules or parts of pretrained models. This not only speeds up the model training process, but also improves the training effect. By transfer learning, we use the pretrained ResNet18 on ImageNet as backbone. The we add a three layers mlp as a simple classifier. The model architecture look like this:\n",
    "\n",
    "<img src=\"./img/res arch.png\" max-witdh=\"50%\" max-height=\"50%\"/>\n",
    "\n",
    "**[1]** Deep Learning the Morphology of Dark Matter Substructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91ddccb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetClf(nn.Module):\n",
    "\n",
    "    def __init__(self, pre_trained):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pre_trained: True if want to use pretrained weight else false\n",
    "        \"\"\"\n",
    "        super(ResNetClf, self).__init__()\n",
    "        self.backbone = models.resnet18(pretrained=pre_trained)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 3)\n",
    "        )\n",
    "        self.backbone.conv1 = Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.backbone.fc = self.classifier\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa2680b",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e6fec2",
   "metadata": {},
   "source": [
    "- **data augmentation:** According paper[1], during training I use the data augmengtation via random translation and random rotation.\n",
    "\n",
    "\n",
    "- **batch_size:** I have tried batch_size=200, batch_size=64, batch_size=128. Results show that batch_size=128 same a better choice. Larger batch_size can improve the computational efficiency through the matrix multiply. More larger batch_size reduces the number of iterations required to compute all the training set, so the time required to achieve the same accuracy becomes larger, and the adjust of parameters becomes slow.\n",
    "\n",
    "\n",
    "- **num_epoch:** 50\n",
    "\n",
    "\n",
    "- **lr:** According to paper[1], I set the lr with value of 1e-4. No decay has been adopted. This dataset is not complicated, no lr decay can also get a acceptable performance.\n",
    "\n",
    "\n",
    "- **train:** When one epoch has finished, model will evaluate it's current performance on the validation dataset.  \n",
    "\n",
    "\n",
    "**Final auc is 99.15%, acc is 94.17%**, which is an acceptable result. Detailed training log can be found in **\"./log.txt\"**\n",
    "\n",
    "**[1]** Deep Learning the Morphology of Dark Matter Substructure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3428780c",
   "metadata": {},
   "source": [
    "## Training Config Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4e243e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    num_epochs = 50\n",
    "    batch_size = 100\n",
    "    # reference from paper \"Deep Learning the Morphology of Dark Matter Substructure\"\n",
    "    lr = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa716c65",
   "metadata": {},
   "source": [
    "## Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "826c8ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from utils import check_accuracy, save_checkpoint\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeaefd0",
   "metadata": {},
   "source": [
    "## Train Function Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d582c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(cfg, train_loader, test_loader, model, optimizer, criterion, need_flatten=False):\n",
    "    \"\"\"\n",
    "    train function\n",
    "    Args:\n",
    "        need_flatten: If only mlp is used, this need to be true.\n",
    "    \"\"\"\n",
    "\n",
    "    acc_per_epoch = []\n",
    "    max_auc = 0.0\n",
    "\n",
    "    # lr scheduler\n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode=\"max\",\n",
    "        factor=0.3,\n",
    "        patience=3,\n",
    "        threshold=0.001,\n",
    "        min_lr=1e-5,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    for epoch in range(cfg.num_epochs):\n",
    "        losses_per_batch = []\n",
    "        start_time = time.time()\n",
    "\n",
    "        # mini batch training\n",
    "        # p_bar = tqdm(enumerate(train_loader), leave=False, total=len(train_loader), file=sys.stdout)\n",
    "        for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
    "            # move data to gpu if cuda is available\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            if need_flatten:\n",
    "                x_batch = x_batch.reshape(x_batch.shape[0], -1)\n",
    "\n",
    "            # forward\n",
    "            scores = model.forward(x_batch)\n",
    "            loss = criterion(scores, y_batch)\n",
    "            losses_per_batch.append(loss.item())\n",
    "\n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # gradient descent step\n",
    "            optimizer.step()\n",
    "\n",
    "        # compute acc and loss\n",
    "        cur_acc, auc, _, _ = check_accuracy(test_loader, model, device, need_flatten)\n",
    "        mean_loss = sum(losses_per_batch) / len(losses_per_batch)\n",
    "        acc_per_epoch.append(cur_acc)\n",
    "\n",
    "        # lr scheduler\n",
    "        # scheduler.step(auc)\n",
    "\n",
    "        # save model\n",
    "        if epoch > 10 and auc > max_auc:\n",
    "            checkpoint = {\n",
    "                \"model\": model.state_dict(),\n",
    "                \"optimizer\": optimizer.state_dict()\n",
    "            }\n",
    "            print(f\"epoch: [{epoch + 1}/{cfg.num_epochs}], \", end=\"\")\n",
    "            save_checkpoint(checkpoint, \"./checkpoint/best_auc_model.pth.tar\")\n",
    "            max_auc = auc\n",
    "\n",
    "        # print log\n",
    "        end_time = time.time()\n",
    "        print(f\"epoch: [{epoch + 1}/{cfg.num_epochs}], \"\n",
    "              f\"loss: {mean_loss:.8f}, \"\n",
    "              f\"acc: {cur_acc.item():.4f}, \"\n",
    "              f\"auc: {auc:.4f}, \"\n",
    "              f\"time used: {(end_time - start_time)/60:.4f}m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a68e34a",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59f0e6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a config\n",
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd396f3",
   "metadata": {},
   "source": [
    "### Data Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4ef737",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_dir = \"./dataset/train\"\n",
    "traindesc_dir = \"./dataset/train description.csv\"\n",
    "\n",
    "# transform\n",
    "train_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomAffine(degrees=(0, 180), translate=(0.2, 0.2)),\n",
    "        transforms.Resize((150, 150))\n",
    "    ])\n",
    "\n",
    "train_set = MyData(traindesc_dir, trainset_dir, transform=train_transform)\n",
    "train_loader = DataLoader(train_set, batch_size=cfg.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfad72c",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaaf305",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNetClf(True).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=cfg.lr)\n",
    "\n",
    "train_fn(cfg, train_loader, test_loader, model, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41d3545",
   "metadata": {},
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b3c84a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from utils import check_accuracy, load_checkpoint, plot_roc\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3fae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a config\n",
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02b7aaa",
   "metadata": {},
   "source": [
    "## Test Data Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50fd417",
   "metadata": {},
   "source": [
    "**You can get pretrained weight <a href=\"https://drive.google.com/file/d/1qBUT7DeNHvFvYAdQRyyNjIKop2CQX23Z/view?usp=sharing\">here</a>**\n",
    "\n",
    "**After downloading it, add it to the directory \"./checkpoint\". Then you can perform the evaluation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f0421b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    ToTensor()\n",
      "    Resize(size=(150, 150), interpolation=bilinear, max_size=None, antialias=None)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "testset_dir = \"./dataset/val\"\n",
    "testdesc_dir = \"./dataset/val description.csv\"\n",
    "pretrained_model = \"./checkpoint/best_auc_model.pth.tar\"\n",
    "\n",
    "test_tranform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((150, 150))\n",
    "])\n",
    "\n",
    "test_set = MyData(testdesc_dir, testset_dir, transform=test_tranform)\n",
    "test_loader = DataLoader(test_set, batch_size=cfg.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fdb3b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Load model from ./checkpoint/best_auc_model.pth.tar\n"
     ]
    }
   ],
   "source": [
    "model = ResNetClf(False).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=cfg.lr)\n",
    "load_checkpoint(pretrained_model, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a1517a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9417333333333334, auc: 0.9914998666666667\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc, auc, y_true, y_pred = check_accuracy(test_loader, model, device)\n",
    "print(f\"acc: {acc.item()}, auc: {auc}\")\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "plot_roc(fpr, tpr, auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e8232b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
